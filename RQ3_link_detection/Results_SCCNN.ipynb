{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24780726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Notebook.\n"
     ]
    }
   ],
   "source": [
    "#Needed Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Starting Notebook.\")\n",
    "\n",
    "sns.set(font_scale = 1.25)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010ebf3a",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88abf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCES = ['Apache', 'Hyperledger', 'IntelDAOS', \n",
    "           'JFrog', 'Jira', 'JiraEcosystem', \n",
    "           'MariaDB', 'MongoDB', 'Qt', \n",
    "           'RedHat', 'Sakai', 'SecondLife', \n",
    "           'Sonatype', 'Spring']\n",
    "# 'Mindville'\n",
    "\n",
    "CONFIG = ['R_LTvNL', 'R_LTvNLOL', 'R_LTOLvNL']\n",
    "LT = 'Duplication'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a221928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_linktypes(SOURCE):\n",
    "    #Loading Issues\n",
    "    filename = '../data/crawl/issues_'+SOURCE.lower()+'.csv'\n",
    "    issues = pd.read_csv(filename, encoding=\"UTF-8\", low_memory=False, sep=';')\n",
    "    \n",
    "    issue_set = set(issues['issue_id'])\n",
    "        \n",
    "    #Loading Links\n",
    "    filename = '../data/crawl/clean_links_'+SOURCE.lower()+'.csv'\n",
    "    links = pd.read_csv(filename, encoding=\"UTF-8\", low_memory=False, index_col=0)\n",
    "    \n",
    "    link_set = set(links['issue_id_1']).union(set(links['issue_id_2']))\n",
    "\n",
    "    num_dups = len(links[links['linktype']=='Duplicate'])\n",
    "        \n",
    "    return len(issues), len(links), len(links.linktype.unique()), round(len(link_set)/len(issue_set), 3), num_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c54fbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = pd.DataFrame(columns = ['Project', '#Issues', '#Links', '#Linktypes', '%IssuesWithLinks', '#NumDups'])\n",
    "j=0\n",
    "for s in SOURCES:\n",
    "    i, l, ltu, pi, nd = print_linktypes(s)\n",
    "    \n",
    "    if s == 'JiraEcosystem':\n",
    "        s = 'JiraEco.'\n",
    "    \n",
    "    overview.loc[j]=[s, i, l, ltu, pi, nd]\n",
    "    \n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ec36509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project</th>\n",
       "      <th>#Issues</th>\n",
       "      <th>#Links</th>\n",
       "      <th>#Linktypes</th>\n",
       "      <th>%IssuesWithLinks</th>\n",
       "      <th>#NumDups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apache</td>\n",
       "      <td>970929</td>\n",
       "      <td>242823</td>\n",
       "      <td>21</td>\n",
       "      <td>0.283</td>\n",
       "      <td>24868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hyperledger</td>\n",
       "      <td>27914</td>\n",
       "      <td>16225</td>\n",
       "      <td>8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IntelDAOS</td>\n",
       "      <td>5557</td>\n",
       "      <td>3222</td>\n",
       "      <td>10</td>\n",
       "      <td>0.555</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JFrog</td>\n",
       "      <td>14769</td>\n",
       "      <td>3206</td>\n",
       "      <td>11</td>\n",
       "      <td>0.298</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jira</td>\n",
       "      <td>265343</td>\n",
       "      <td>98122</td>\n",
       "      <td>19</td>\n",
       "      <td>0.477</td>\n",
       "      <td>21350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JiraEco.</td>\n",
       "      <td>40602</td>\n",
       "      <td>10911</td>\n",
       "      <td>18</td>\n",
       "      <td>0.328</td>\n",
       "      <td>1721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MariaDB</td>\n",
       "      <td>31229</td>\n",
       "      <td>14618</td>\n",
       "      <td>8</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MongoDB</td>\n",
       "      <td>90629</td>\n",
       "      <td>37545</td>\n",
       "      <td>13</td>\n",
       "      <td>0.426</td>\n",
       "      <td>6548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Qt</td>\n",
       "      <td>140237</td>\n",
       "      <td>35855</td>\n",
       "      <td>8</td>\n",
       "      <td>0.289</td>\n",
       "      <td>3827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RedHat</td>\n",
       "      <td>315797</td>\n",
       "      <td>106200</td>\n",
       "      <td>18</td>\n",
       "      <td>0.389</td>\n",
       "      <td>5436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sakai</td>\n",
       "      <td>49204</td>\n",
       "      <td>19057</td>\n",
       "      <td>7</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SecondLife</td>\n",
       "      <td>1865</td>\n",
       "      <td>630</td>\n",
       "      <td>6</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sonatype</td>\n",
       "      <td>77837</td>\n",
       "      <td>4289</td>\n",
       "      <td>11</td>\n",
       "      <td>0.075</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Spring</td>\n",
       "      <td>69100</td>\n",
       "      <td>14461</td>\n",
       "      <td>9</td>\n",
       "      <td>0.256</td>\n",
       "      <td>1744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Project #Issues  #Links #Linktypes  %IssuesWithLinks #NumDups\n",
       "0        Apache  970929  242823         21             0.283    24868\n",
       "1   Hyperledger   27914   16225          8             0.551      634\n",
       "2     IntelDAOS    5557    3222         10             0.555      117\n",
       "3         JFrog   14769    3206         11             0.298      639\n",
       "4          Jira  265343   98122         19             0.477    21350\n",
       "5      JiraEco.   40602   10911         18             0.328     1721\n",
       "6       MariaDB   31229   14618          8             0.445     1374\n",
       "7       MongoDB   90629   37545         13             0.426     6548\n",
       "8            Qt  140237   35855          8             0.289     3827\n",
       "9        RedHat  315797  106200         18             0.389     5436\n",
       "10        Sakai   49204   19057          7             0.422     1807\n",
       "11   SecondLife    1865     630          6             0.398        0\n",
       "12     Sonatype   77837    4289         11             0.075      337\n",
       "13       Spring   69100   14461          9             0.256     1744"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82848e0b",
   "metadata": {},
   "source": [
    "## Loading Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_projects = []\n",
    "\n",
    "for s in SOURCES:\n",
    "    valid = True\n",
    "    for c in CONFIG:\n",
    "        filename = 'results_v1/sccnn_'+s.lower()+'_'+LT+'_'+c+'_metrics.csv'\n",
    "        metrics_df = pd.read_csv(filename, encoding=\"UTF-8\", low_memory=False)\n",
    "        \n",
    "        LT_mets = metrics_df.iloc[0].values.tolist()[1:]\n",
    "        NL_mets = metrics_df.iloc[1].values.tolist()[1:]\n",
    "        OL_mets = metrics_df.iloc[2].values.tolist()[1:]\n",
    "  \n",
    "        valid = valid and not(np.isnan(LT_mets + OL_mets + NL_mets).any())\n",
    "          \n",
    "    if valid:\n",
    "        valid_projects.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b785c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apache',\n",
       " 'Hyperledger',\n",
       " 'IntelDAOS',\n",
       " 'JFrog',\n",
       " 'Jira',\n",
       " 'JiraEco.',\n",
       " 'MariaDB',\n",
       " 'MongoDB',\n",
       " 'Qt',\n",
       " 'RedHat',\n",
       " 'Sakai',\n",
       " 'Sonatype',\n",
       " 'Spring']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpfptnfn(conf_mat):\n",
    "    \n",
    "    tp = conf_mat.loc[\"DUPLICATION\"][1] \n",
    "    fn = conf_mat.loc[\"DUPLICATION\"][0] \n",
    "    fp = conf_mat.loc[\"NON-LINKS\"][1] \n",
    "    tn = conf_mat.loc[\"NON-LINKS\"][0] \n",
    "    \n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(c, trad):\n",
    "    avg_d_pre = []\n",
    "    avg_d_rec = []\n",
    "    avg_d_f1 = []\n",
    "\n",
    "    avg_nl_pre = []\n",
    "    avg_nl_rec = []\n",
    "    avg_nl_f1 = []\n",
    "\n",
    "    avg_ol_0 = []\n",
    "    avg_ol_1 = []\n",
    "\n",
    "    avg_acc = []\n",
    "\n",
    "    avg_pre = []\n",
    "    avg_rec = []\n",
    "    avg_f1 = []\n",
    "\n",
    "    for s in valid_projects:\n",
    "#         print(s.upper())\n",
    "        filename = 'results_v1/sccnn_latenight_'+s.lower()+'_'+LT+'_'+c+'_confmat.csv'\n",
    "        confmat_df = pd.read_csv(filename, encoding=\"UTF-8\", low_memory=False, index_col='Class')\n",
    "        confmat_df = pd.DataFrame(confmat_df.values, index=['DUPLICATION', 'OTHER-LINKS', 'NON-LINKS'])\n",
    "#         print(confmat_df.transpose())\n",
    "        \n",
    "    #     print(confmat_df)\n",
    "    #     print(confmat_df.transpose()/confmat_df.sum(axis=1))\n",
    "    #     print((confmat_df.transpose()/confmat_df.sum(axis=1)).index)\n",
    "\n",
    "        avg_ol_0.append((confmat_df.transpose()/confmat_df.sum(axis=1)).loc[0][\"OTHER-LINKS\"])\n",
    "        avg_ol_1.append((confmat_df.transpose()/confmat_df.sum(axis=1)).loc[1][\"OTHER-LINKS\"])\n",
    "\n",
    "#         print(\"OL 0: \"+ str(np.round((confmat_df.transpose()/confmat_df.sum(axis=1)).loc['0'][\"OTHER-LINKS\"], 3)))\n",
    "#         print(\"OL 1: \"+ str(np.round((confmat_df.transpose()/confmat_df.sum(axis=1)).loc['1'][\"OTHER-LINKS\"], 3)))\n",
    "        \n",
    "        if not trad:\n",
    "            if c == 'R_LTOLvNL':\n",
    "                new_confmat = [[confmat_df.loc[\"DUPLICATION\"][0]+confmat_df.loc[\"OTHER-LINKS\"][0], \n",
    "                                confmat_df.loc[\"DUPLICATION\"][1]+confmat_df.loc[\"OTHER-LINKS\"][1]],\n",
    "                               [confmat_df.loc[\"NON-LINKS\"][0],\n",
    "                                confmat_df.loc[\"NON-LINKS\"][1]]]\n",
    "                new_confmat_df = pd.DataFrame(new_confmat, index=['DUPLICATION', 'NON-LINKS'])\n",
    "            else:\n",
    "                new_confmat = [[confmat_df.loc[\"DUPLICATION\"][0], \n",
    "                                confmat_df.loc[\"DUPLICATION\"][1]],\n",
    "                               [confmat_df.loc[\"OTHER-LINKS\"][0]+confmat_df.loc[\"NON-LINKS\"][0],\n",
    "                                confmat_df.loc[\"OTHER-LINKS\"][1]+confmat_df.loc[\"NON-LINKS\"][1]]]\n",
    "                new_confmat_df = pd.DataFrame(new_confmat, index=['DUPLICATION', 'NON-LINKS'])\n",
    "            confmat_df = new_confmat_df\n",
    "\n",
    "        tp, fp, tn, fn = get_tpfptnfn(confmat_df)\n",
    "        \n",
    "        d_pre = tp/(tp+fp)\n",
    "        d_rec = tp/(tp+fn)\n",
    "        d_f1 = 2*(d_pre*d_rec)/(d_pre+d_rec)\n",
    "\n",
    "        avg_d_pre.append(d_pre)\n",
    "        avg_d_rec.append(d_rec)\n",
    "        avg_d_f1.append(d_f1)\n",
    "\n",
    "        nl_pre = tn/(tn+fn)\n",
    "        nl_rec = tn/(tn+fp)\n",
    "        nl_f1 = 2*(nl_pre*nl_rec)/(nl_pre+nl_rec)\n",
    "\n",
    "        avg_nl_pre.append(nl_pre)\n",
    "        avg_nl_rec.append(nl_rec)\n",
    "        avg_nl_f1.append(nl_f1)\n",
    "\n",
    "        pre = (d_pre+nl_pre)/2\n",
    "        rec = (d_rec+nl_rec)/2\n",
    "        f1 = 2*(pre*rec)/(pre+rec)\n",
    "        \n",
    "        avg_pre.append(pre)\n",
    "        avg_rec.append(rec)\n",
    "        avg_f1.append(f1)\n",
    "        \n",
    "        acc = (tp+tn)/(tp+fp+fn+tn)\n",
    "\n",
    "        avg_acc.append(acc)\n",
    "\n",
    "    print(\"+++++++++++++++++\")\n",
    "    print(\"ACC: \"+str(round(np.mean(avg_acc),2)))\n",
    "    print(\"+++++++++++++++++\")\n",
    "    print(\"PRE: \"+str(round(np.mean(avg_pre),2)))\n",
    "    print(\"REC: \"+str(round(np.mean(avg_rec),2)))\n",
    "    print(\"F1: \"+str(round(np.mean(avg_f1),2)))\n",
    "    print(\"+++++++++++++++++\")\n",
    "    print(\"D PRE: \"+str(round(np.mean(avg_d_pre),2)))\n",
    "    print(\"D REC: \"+str(round(np.mean(avg_d_rec),2)))\n",
    "    print(\"D F1: \"+str(round(np.mean(avg_d_f1),2)))\n",
    "    print(\"+++++++++++++++++\")\n",
    "    print(\"NL PRE: \"+str(round(np.mean(avg_nl_pre),2)))\n",
    "    print(\"NL REC: \"+str(round(np.mean(avg_nl_rec),2)))\n",
    "    print(\"NL F1: \"+str(round(np.mean(avg_nl_f1),2)))\n",
    "    print(\"+++++++++++++++++\")\n",
    "    print(\"OL 0: \"+str(round(np.mean(avg_ol_0),2)))\n",
    "    print(\"OL 1: \"+str(round(np.mean(avg_ol_1),2)))\n",
    "\n",
    "    print(\"OL STD: \"+str(round(np.std(avg_ol_0),2)))\n",
    "\n",
    "    \n",
    "    res_dict = {\n",
    "            'ACC' : avg_acc,\n",
    "            'Pre': avg_pre,\n",
    "            'Rec': avg_rec,\n",
    "            'F1': avg_f1,\n",
    "            'D_Pre': avg_d_pre,\n",
    "            'D_Rec': avg_d_rec,\n",
    "            'D_F1': avg_d_f1,\n",
    "            'NL_Pre': avg_nl_pre,\n",
    "            'NL_Rec': avg_nl_rec,\n",
    "            'NL_F1': avg_nl_f1,\n",
    "            'OL_Corr': avg_ol_0,\n",
    "          }\n",
    "\n",
    "    res_data= pd.DataFrame(res_dict, index=[valid_projects])\n",
    "    \n",
    "    return res_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('R_LTvNL', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('R_LTvNL', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('R_LTvNLOL', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('R_LTvNLOL', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('R_LTOLvNL', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results('R_LTOLvNL', False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
